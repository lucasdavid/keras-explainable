
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Grad-CAM &#8212; Keras Explainable</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/thebelab-helper.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="TTA Grad-CAM" href="tta_gradcam.html" />
    <link rel="prev" title="Full Gradients" href="../saliency/fullgrad.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Keras Explainable</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../readme.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../explaining.html">
   Explaining
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../index.html">
   Methods
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../saliency/gradients.html">
     Gradient Back-propagation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../saliency/smoothgrad.html">
     Smooth-Grad
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../saliency/fullgrad.html">
     Full-Grad
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Grad-CAM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tta_gradcam.html">
     TTA Grad-CAM
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../wsol.html">
   WSSL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../contributing.html">
   Contributions &amp; Help
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../license.html">
   License
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../authors.html">
   Authors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../changelog.html">
   Changelog
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../api/modules.html">
   Module Reference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../api/keras_explainable.html">
     keras_explainable package
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../api/keras_explainable.engine.html">
       keras_explainable.engine package
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../api/keras_explainable.methods.html">
       keras_explainable.methods package
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/lucasdavid/keras-explainable"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/methods/cams/gradcam.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#breakdown-of-model-exposure-and-grad-cam">
   Breakdown of Model Exposure and Grad-CAM
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Grad-CAM</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#breakdown-of-model-exposure-and-grad-cam">
   Breakdown of Model Exposure and Grad-CAM
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="grad-cam">
<h1>Grad-CAM<a class="headerlink" href="#grad-cam" title="Permalink to this headline">#</a></h1>
<p>This example illustrate how to explain predictions of a Convolutional Neural
Network (CNN) using Grad-CAM. This can be easily achieved with the following
code template snippet:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">keras_explainable</span> <span class="k">as</span> <span class="nn">ke</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">ResNet50V2</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ke</span><span class="o">.</span><span class="n">inspection</span><span class="o">.</span><span class="n">expose</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="n">scores</span><span class="p">,</span> <span class="n">cams</span> <span class="o">=</span> <span class="n">ke</span><span class="o">.</span><span class="n">gradcam</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
<p>In this page, we describe how to obtain <em>Class Activation Maps</em> (CAMs) from a
trained Convolutional Neural Network (CNN) with respect to an input signal
(an image, in this case) using the Grad-CAM visualization method.
Said maps can be used to explain the model’s predictions, determining regions
which most contributed to its effective output.</p>
<p>Grad-CAM is a form of visualizing regions that most contributed to the output
of a given logit unit of a neural network, often times associated with the
prediction of the occurrence of a class in the problem domain. This method
is first described in the following article:</p>
<p>Selvaraju, R. R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., &amp; Batra, D.
(2017). Grad-cam: Visual explanations from deep networks via gradient-based
localization. In Proceedings of the IEEE international conference on computer
vision (pp. 618-626).</p>
<p>Briefly, this can be achieved with the following template snippet:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">keras_explainable</span> <span class="k">as</span> <span class="nn">ke</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">logits</span><span class="p">,</span> <span class="n">maps</span> <span class="o">=</span> <span class="n">ke</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
<p>We describe bellow these lines in detail.</p>
<div class="jupyter_cell docutils container">
<div class="cell_output docutils container">
</div>
</div>
<p>Firstly, we employ the <code class="xref py py-class docutils literal notranslate"><span class="pre">ResNet101</span></code> network pre-trained over the
ImageNet dataset:</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">WEIGHTS</span> <span class="o">=</span> <span class="s1">&#39;imagenet&#39;</span>

<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">*</span><span class="n">SIZES</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;inputs&#39;</span><span class="p">)</span>

<span class="n">rn101</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">ResNet101V2</span><span class="p">(</span>
  <span class="n">input_tensor</span><span class="o">=</span><span class="n">input_tensor</span><span class="p">,</span>
  <span class="n">classifier_activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
  <span class="n">weights</span><span class="o">=</span><span class="n">WEIGHTS</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;ResNet101 with </span><span class="si">{</span><span class="n">WEIGHTS</span><span class="si">}</span><span class="s1"> pre-trained weights loaded.&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Spatial map sizes: </span><span class="si">{</span><span class="n">rn101</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="s1">&#39;avg_pool&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>ResNet101 with imagenet pre-trained weights loaded.
Spatial map sizes: (None, 10, 10, 2048)
</pre></div>
</div>
</div>
</div>
<p>We can feed-foward the samples once and get the predicted classes for each sample.
Besides making sure the model is outputing the expected classes, this step is
required in order to determine the most activating units in the <em>logits</em> layer,
which improves performance of the explaining methods.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">resnet_v2</span><span class="o">.</span><span class="n">preprocess_input</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">prec</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">rn101</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">explaining_units</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># First most likely class of each sample.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<p>Grad-CAM works by computing the differential of an activation function,
usually associated with the prediction of a given class, with respect to pixels
contained in the activation map retrieved from an intermediate convolutional
signal (oftentimes advent from the last convolutional layer).</p>
<p>CAM-based methods implemented here expect the model to output both logits and
activation signal, so their respective representative tensors are exposed and
the jacobian can be computed from the former with respect to the latter.
Hence, we modify the current <cite>rn101</cite> model — which only output logits at this
time — to expose both activation maps and logits signals:</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rn101_exposed</span> <span class="o">=</span> <span class="n">ke</span><span class="o">.</span><span class="n">inspection</span><span class="o">.</span><span class="n">expose</span><span class="p">(</span><span class="n">rn101</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">cams</span> <span class="o">=</span> <span class="n">ke</span><span class="o">.</span><span class="n">gradcam</span><span class="p">(</span><span class="n">rn101_exposed</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">explaining_units</span><span class="p">)</span>

<span class="n">ke</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">visualize</span><span class="p">(</span>
  <span class="n">images</span><span class="p">,</span>
  <span class="n">overlays</span><span class="o">=</span><span class="n">cams</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">SIZES</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
  <span class="n">cols</span><span class="o">=</span><span class="mi">4</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/gradcam_3_0.png" src="../../_images/gradcam_3_0.png" />
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To increase efficiency, we sub-select only the top <span class="math notranslate nohighlight">\(K\)</span> scoring
classification units to explain. The jacobian will only be computed for
these <span class="math notranslate nohighlight">\(NK\)</span> outputs.</p>
</div>
<section id="breakdown-of-model-exposure-and-grad-cam">
<h2>Breakdown of Model Exposure and Grad-CAM<a class="headerlink" href="#breakdown-of-model-exposure-and-grad-cam" title="Permalink to this headline">#</a></h2>
<p>The function <a class="reference internal" href="../../api/keras_explainable.html#keras_explainable.inspection.expose" title="keras_explainable.inspection.expose"><code class="xref py py-func docutils literal notranslate"><span class="pre">keras_explainable.inspection.expose()</span></code></a> will take a
<code class="xref py py-class docutils literal notranslate"><span class="pre">keras.Model</span></code> as argument and instantiate a new model that outputs
both logits and the activation signal immediately before the
<em>Global Average Pooling</em> layer.</p>
<p>Under the hood of our example,
<a href="#id1"><span class="problematic" id="id2">:py:function:`keras_explainable.inspection.expose`</span></a> is simply
collecting the input and output signals of the global pooling
and predictions layer, respectively:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">activations</span> <span class="o">=</span> <span class="n">rn101</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="s1">&#39;avg_pool&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">input</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">rn101</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="s1">&#39;predictions&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">output</span>

<span class="n">rn101_exposed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">rn101</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="n">scores</span><span class="p">,</span> <span class="n">activations</span><span class="p">])</span>
</pre></div>
</div>
<p>You can also provide hints regarding the argument and output signals, if
your model’s topology is more complex or if you simply wish to compute the
Grad-CAM with respect to other layer than the last convolutional one:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rn101_exposed</span> <span class="o">=</span> <span class="n">ke</span><span class="o">.</span><span class="n">inspection</span><span class="o">.</span><span class="n">expose</span><span class="p">(</span><span class="n">rn101</span><span class="p">,</span> <span class="s1">&#39;conv5_out&#39;</span><span class="p">,</span> <span class="s1">&#39;predictions&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>For nested models that were created from different Input objects, you can
further specify which nodes to access within each layer, which maintains
the computation graph connected:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Activation</span>
<span class="kn">from</span> <span class="nn">keras.applications</span> <span class="kn">import</span> <span class="n">ResNet101V2</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">backbone</span> <span class="o">=</span> <span class="n">ResNet101V2</span><span class="p">(</span><span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pooling</span><span class="o">=</span><span class="s1">&#39;avg&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
  <span class="n">inputs</span><span class="p">,</span>
  <span class="n">backbone</span><span class="p">,</span>
  <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;logits&#39;</span><span class="p">),</span>
  <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">),</span>
<span class="p">])</span>

<span class="n">rn101_exposed</span> <span class="o">=</span> <span class="n">ke</span><span class="o">.</span><span class="n">inspection</span><span class="o">.</span><span class="n">expose</span><span class="p">(</span>
  <span class="n">rn101</span><span class="p">,</span>
  <span class="n">arguments</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;rn101.avg_pool&#39;</span><span class="p">,</span>
    <span class="s1">&#39;link&#39;</span><span class="p">:</span> <span class="s1">&#39;input&#39;</span><span class="p">,</span>
    <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="mi">1</span>
  <span class="p">},</span>
  <span class="n">outputs</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span>
<span class="p">)</span>
</pre></div>
</div>
<p>As for the <code class="xref py py-func docutils literal notranslate"><span class="pre">ke.gradcam()</span></code> function, it is only a shortcut for
<code class="docutils literal notranslate"><span class="pre">ke.explain(ke.methods.cams.gradcam,</span> <span class="pre">model,</span> <span class="pre">inputs,</span> <span class="pre">...)</span></code>.</p>
<p>All explaining methods can also be called directly:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gradcam</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">ke</span><span class="o">.</span><span class="n">methods</span><span class="o">.</span><span class="n">cams</span><span class="o">.</span><span class="n">gradcam</span><span class="p">,</span> <span class="n">reduce_retracing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">logits</span><span class="p">,</span> <span class="n">cams</span> <span class="o">=</span> <span class="n">gradcam</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">explaining_units</span><span class="p">)</span>

<span class="n">cams</span> <span class="o">=</span> <span class="n">ke</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">positive_normalize</span><span class="p">(</span><span class="n">cams</span><span class="p">)</span>
<span class="n">cams</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">cams</span><span class="p">,</span> <span class="n">SIZES</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
<p>Following the original Grad-CAM paper, we only consider the positive
contributing regions in the creation of the CAMs, crunching negatively
contributing and non-related regions together.
This is done automatically by <code class="xref py py-func docutils literal notranslate"><span class="pre">ke.gradcam()</span></code>, which assigns
the default value <code class="xref py py-func docutils literal notranslate"><span class="pre">filters.positive_normalize()</span></code> to the
<code class="docutils literal notranslate"><span class="pre">postprocessing</span></code> parameter.</p>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../saliency/fullgrad.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Full Gradients</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="tta_gradcam.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">TTA Grad-CAM</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
      &copy; Copyright 2022, Lucas David.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>