<!DOCTYPE html>
<html lang="en" >
<head>
    <meta charset="utf-8">
    <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    <title>Weakly Supervised Object Localization and Semantic Segmentation</title>
    

    <link rel="stylesheet" href="_static/css/redactor.css" type="text/css" />
    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <link rel="stylesheet" href="_static/css/redactor.css" type="text/css" />
    
    <link rel="stylesheet" href="_static/jupyter-sphinx.css" type="text/css" />
    
    <link rel="stylesheet" href="_static/thebelab.css" type="text/css" />
    
    <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
    
    
    <link rel="index" title="Index" href="genindex.html"/>
    <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="Keras Explainable" href="index.html"/>
    <link rel="next" title="Contributing" href="contributing.html"/>
    <link rel="prev" title="TTA CAM" href="methods/cams/ttacam.html"/> 
</head>

<body role="document">
     

    
<a href="#" id="js-navigation-toggle" class="navigation-toggle">
    <i class="mdi mdi-menu"></i><i class="mdi mdi-close"></i>
</a>

<section class="site-sidebar">

<nav>


    <a href="index.html" class="branding-link">
    
        keras-explainable
    
    
    
        
        
            <span class="branding-link__version">
                0.0.2
            </span>
        
    
    </a>

    
<section role="search">
    <form action="search.html" method="get" class="site-searchform">
        <input type="text" name="q" placeholder="Search docs" />
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
      </form>
</section>



    <section class="site-nav">
    
    
        <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="readme.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="explaining.html">Explaining</a></li>
<li class="toctree-l1"><a class="reference internal" href="exposure.html">Exposure</a></li>
<li class="toctree-l1"><a class="reference internal" href="methods/index.html">Methods</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">WSSL &amp; WSSS</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributions &amp; Help</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">Authors</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/modules.html">Module Reference</a></li>
</ul>

    
    </section>

</nav>

</section>

    <main class="site-main" role="main">
        











<nav class="site-breadcrumbs">
    <ul>
    
        <li>
            <a href="index.html">Docs</a> /
        </li>
        
        <li class="site-breadcrumbs__leaf">Weakly Supervised Object Localization and Semantic Segmentation</li>
    
    </ul>
</nav>
        <section class="site-content">
            <div class="container">
                
  <section id="weakly-supervised-object-localization-and-semantic-segmentation">
<h1>Weakly Supervised Object Localization and Semantic Segmentation<a class="headerlink" href="#weakly-supervised-object-localization-and-semantic-segmentation" title="Permalink to this heading">¶</a></h1>
<p>Object localization and segmentation cues can be extracted from models
trained over multi-label datasets in a weakly supervised setup.</p>
<p>An example of this technique is OC-CSE, which was first described in
the paper “Unlocking the potential of ordinary classifier: Class-specific
adversarial erasing framework for weakly supervised semantic segmentation.”,
by Kweon et al. (2021) [<a class="reference external" href="https://openaccess.thecvf.com/content/ICCV2021/html/Kweon_Unlocking_the_Potential_of_Ordinary_Classifier_Class-Specific_Adversarial_Erasing_Framework_ICCV_2021_paper.html">link</a>].
Its original code (written in PyTorch) is available at
<a class="reference external" href="https://github.com/KAIST-vilab/OC-CSE">KAIST-vilab/OC-CSE</a>, but
we will actually load its TensorFlow alternative, available at
<a class="reference external" href="https://github.com/lucasdavid/resnet38d-tf">lucasdavid/resnet38d-tf</a>:</p>
<div class="jupyter_cell docutils container">
<div class="cell_output docutils container">
</div>
</div>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">COLORS</span> <span class="o">=</span> <span class="n">pascal_voc_colors</span><span class="p">()</span>
<span class="n">CLASSES</span> <span class="o">=</span> <span class="n">pascal_voc_classes</span><span class="p">()</span>
<span class="n">WEIGHTS</span> <span class="o">=</span> <span class="s1">&#39;docs/_build/data/resnet38d_voc2012_occse.h5&#39;</span>

<span class="o">!</span> mkdir -p docs/_build/data
<span class="o">!</span> wget -q -nc https://raw.githubusercontent.com/lucasdavid/resnet38d-tf/main/resnet38d.py
<span class="o">!</span> wget -qnc https://github.com/lucasdavid/resnet38d-tf/releases/download/0.0.1/resnet38d_voc2012_occse.h5 -P docs/_build/data/

<span class="kn">from</span> <span class="nn">resnet38d</span> <span class="kn">import</span> <span class="n">ResNet38d</span>

<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;inputs&quot;</span><span class="p">)</span>
<span class="n">rn38d</span> <span class="o">=</span> <span class="n">ResNet38d</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">=</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">WEIGHTS</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ResNet38-d with </span><span class="si">{</span><span class="n">WEIGHTS</span><span class="si">}</span><span class="s2"> pre-trained weights loaded.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Spatial map sizes: </span><span class="si">{</span><span class="n">rn38d</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="s1">&#39;s5/ac&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="o">!</span> rm resnet38d.py
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>ResNet38-d with docs/_build/data/resnet38d_voc2012_occse.h5 pre-trained weights loaded.
Spatial map sizes: (None, None, None, 4096)
</pre></div>
</div>
</div>
</div>
<p>We can feed-forward the samples once and get the predicted classes for each sample.
Besides making sure the model is outputting the expected classes, this step is
required in order to determine the most activating units in the <em>logits</em> layer,
which improves performance of the explaining methods.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">imagenet_utils</span><span class="o">.</span><span class="n">preprocess_input</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">prec</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;torch&#39;</span><span class="p">)</span>
<span class="n">probs</span> <span class="o">=</span> <span class="n">rn38d</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<p>Finally, we can simply run all available explaining methods:</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rn38d</span> <span class="o">=</span> <span class="n">ke</span><span class="o">.</span><span class="n">inspection</span><span class="o">.</span><span class="n">expose</span><span class="p">(</span><span class="n">rn38d</span><span class="p">,</span> <span class="s2">&quot;s5/ac&quot;</span><span class="p">,</span> <span class="s1">&#39;avg_pool&#39;</span><span class="p">)</span>

<span class="c1"># Vanilla CAM</span>
<span class="n">_</span><span class="p">,</span> <span class="n">cams</span> <span class="o">=</span> <span class="n">ke</span><span class="o">.</span><span class="n">cam</span><span class="p">(</span><span class="n">rn38d</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># TTA-CAM</span>
<span class="n">tta_cam_method</span> <span class="o">=</span> <span class="n">ke</span><span class="o">.</span><span class="n">methods</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">tta</span><span class="p">(</span>
  <span class="n">ke</span><span class="o">.</span><span class="n">methods</span><span class="o">.</span><span class="n">cams</span><span class="o">.</span><span class="n">cam</span><span class="p">,</span>
  <span class="n">scales</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>
  <span class="n">hflip</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">tta_cams</span> <span class="o">=</span> <span class="n">ke</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span>
  <span class="n">tta_cam_method</span><span class="p">,</span>
  <span class="n">rn38d</span><span class="p">,</span>
  <span class="n">inputs</span><span class="p">,</span>
  <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
  <span class="n">postprocessing</span><span class="o">=</span><span class="n">ke</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">positive_normalize</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<p>Explaining maps can be converted into color maps,
respecting the conventional Pascal color mapping:</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">cams_to_colors</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">maps</span><span class="p">,</span> <span class="n">colors</span><span class="p">):</span>
  <span class="n">overlays</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">):</span>
    <span class="n">l</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">colors</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">maps</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="n">l</span><span class="p">]</span>
    <span class="n">o</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;dc,hwd-&gt;hwc&#39;</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">overlays</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">o</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">overlays</span>

<span class="n">cam_overlays</span> <span class="o">=</span> <span class="n">cams_to_colors</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">cams</span><span class="p">,</span> <span class="n">COLORS</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">21</span><span class="p">])</span>
<span class="n">tta_overlays</span> <span class="o">=</span> <span class="n">cams_to_colors</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">tta_cams</span><span class="p">,</span> <span class="n">COLORS</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">21</span><span class="p">])</span>

<span class="n">ke</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">visualize</span><span class="p">([</span><span class="o">*</span><span class="n">images</span><span class="p">,</span> <span class="o">*</span><span class="n">cam_overlays</span><span class="p">,</span> <span class="o">*</span><span class="n">tta_overlays</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/wsol_4_0.png" src="_images/wsol_4_0.png" />
</div>
</div>
</section>


            </div>

        </section>

        
            <nav class="site-bottom-navigation" role="navigation">
            
                <a href="contributing.html" class="btn btn--primary btn--next right"
                    title="Contributing" accesskey="n">
                    Next
                </a>
            
            
                <a href="methods/cams/ttacam.html" class="btn btn--primary btn--prev"
                    title="TTA CAM" accesskey="p">
                    Previous
                </a>
            
            </nav>
        

        
            <div class="source-link">
            
                
                    <a href="_sources/wsol.rst.txt" rel="nofollow">
                        <i class="mdi mdi-code-tags"></i>
                        View page source
                    </a>
                
            
            </div>
        



    </main>

    <footer class="site-footer">
<div class="container">

    <div role="contentinfo">
        <p>
                &copy; Copyright 2022, Lucas David.
        </p>
    </div> 

</div>
</footer>

    

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'',
            VERSION:'0.0.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
    <script type="text/javascript" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/sphinx_highlight.js"></script>
    <script type="text/javascript" src="_static/thebelab-helper.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script type="text/javascript" src="_static/js/theme-min.js"></script> 
</body>
</html>